<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>constriction.stream.model API documentation</title>
<meta name="description" content="Entropy models and model families for use with any of the stream codes from the sister
modules [`stack`](stack.html), [`queue`](queue.html), and â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>constriction.stream.model</code></h1>
</header>
<section id="section-intro">
<p>Entropy models and model families for use with any of the stream codes from the sister
modules <a href="stack.html"><code>stack</code></a>, <a href="queue.html"><code>queue</code></a>, and <a href="chain.html"><code>chain</code></a>.</p>
<p>This module provides tools to define probability distributions over symbols in fixed
point arithmetic, so that the models (more precisely, their cumulative distributions
functions) are <em>exactly</em> invertible without any rounding errors. Being exactly
invertible is crucial for for data compression since even tiny rounding errors can have
catastrophic consequences in an entropy coder (this issue is discussed in the
<a href="chain.html#motivation">motivating example of the <code>ChainCoder</code></a>). Further, the entropy
models in this module all have a well-defined domain, and they always assign a nonzero
probability to all symbols within this domain, even if the symbol is in the tail of some
distribution where its true probability would be lower than the smallest value that is
representable in the employed fixed point arithmetic. This ensures that symbols from the
well-defined domain of a model can, in principle, always be encoded without throwing an
error (symbols with the smallest representable probability will, however, have a very
high bitrate of 24 bits).</p>
<h2 id="concrete-models-vs-model-families">Concrete Models vs. Model Families</h2>
<p>The entropy models in this module can be instantiated in two different ways:</p>
<ul>
<li>(a) as <em>concrete</em> models that are fully parameterized; simply provide all model
parameters to the constructor of the model (e.g., the mean and standard deviation of a
<a href="#constriction.stream.model.QuantizedGaussian"><code>QuantizedGaussian</code></a>, or the domain of a
<a href="#constriction.stream.model.Uniform"><code>Uniform</code></a> model). You can use a concrete model
to either encode or decode single symbols, or to efficiently encode or decode a whole
array of <em>i.i.d.</em> symbols (i.e., using the same model for each symbol in the array,
see first example below).</li>
<li>(b) as model <em>families</em>, i.e., models that still have some free parameters (again,
like the mean and standard deviation of a <code><a title="constriction.stream.model.QuantizedGaussian" href="#constriction.stream.model.QuantizedGaussian">QuantizedGaussian</a></code>, or the range of a
<code><a title="constriction.stream.model.Uniform" href="#constriction.stream.model.Uniform">Uniform</a></code> distribution); simply leave out any optional model parameters when calling
the model constructor. When you then use the resulting model family to encode or
decode an array of symbols, you can provide <em>arrays</em> of model parameters to the encode
and decode methods of the employed entropy coder. This will allow you to use
individual model parameters for each symbol, see second example below (this is more
efficient than constructing a new concrete model for each symbol and looping over the
symbols in Python).</li>
</ul>
<h2 id="examples">Examples</h2>
<p>Constructing and using a <em>concrete</em> <a href="#constriction.stream.model.QuantizedGaussian"><code>QuantizedGaussian</code></a>
model with mean 12.6 and standard deviation 7.3, and which is quantized to integers on the domain
{-100, -99, &hellip;, 100}:</p>
<pre><code class="language-python">model = constriction.stream.model.QuantizedGaussian(-100, 100, 12.6, 7.3)

# Encode and decode an example message:
symbols = np.array([12, 15, 4, -2, 18, 5], dtype=np.int32)
coder = constriction.stream.stack.AnsCoder() # (RangeEncoder also works)
coder.encode_reverse(symbols, model)
print(coder.get_compressed()) # (prints: [745994372, 25704])

reconstructed = coder.decode(model, 6) # (decodes 6 i.i.d. symbols)
assert np.all(reconstructed == symbols) # (verify correctness)
</code></pre>
<p>We can generalize the above example and use model-specific means and standard deviations by
constructing and using a model <em>family</em> instead of a concrete model, and by providing arrays
of model parameters to the encode and decode methods:</p>
<pre><code class="language-python">model_family = constriction.stream.model.QuantizedGaussian(-100, 100)
# Note: we omitted the mean and standard deviation, but the quantization range
#       {-100, ..., 100} must always be specified when constructing the model.

# Define arrays of model parameters (means and standard deviations):
symbols = np.array([12,   15,   4,   -2,   18,   5  ], dtype=np.int32)
means   = np.array([13.2, 17.9, 7.3, -4.2, 25.1, 3.2], dtype=np.float64)
stds    = np.array([ 3.2,  4.7, 5.2,  3.1,  6.3, 2.9], dtype=np.float64)

# Encode and decode an example message:
coder = constriction.stream.stack.AnsCoder() # (RangeEncoder also works)
coder.encode_reverse(symbols, model_family, means, stds)
print(coder.get_compressed()) # (prints: [2051958011, 1549])

reconstructed = coder.decode(model_family, means, stds)
assert np.all(reconstructed == symbols) # (verify correctness)
</code></pre>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="constriction.stream.model.Bernoulli"><code class="flex name class">
<span>class <span class="ident">Bernoulli</span></span>
<span>(</span><span>self, p=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Bernoulli distribution over the alphabet {0, 1}.</p>
<h2 id="model-parameter">Model Parameter</h2>
<p>The model parameter can either be specified as a scalar when constructing the model, or
as a rank-1 numpy array with <code>dtype=np.float64</code> when calling the entropy coder's encode
or decode method (see <a href="#concrete-models-vs-model-families">discussion above</a>). Note
that, in the latter case, you still have to <em>call</em> the constructor of the model, i.e.:
<code>model_family = constriction.stream.model.Bernoulli()</code> &mdash; note the trailing <code>()</code>.</p>
<ul>
<li><strong>p</strong> &mdash; the probability for the symbol being <code>1</code> rather than <code>0</code>. Must be between
0.0 and 1.0 (both inclusive). Note that, even if you set <code>p = 0.0</code> or <code>p = 1.0</code>,
<code><a title="constriction" href="../index.html">constriction</a></code> still assigns a tiny probability to the disallowed outcome so that both
symbols <code>0</code> and <code>1</code> can always be encoded, albeit at a potentially large cost in
bitrate.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Model</li>
</ul>
</dd>
<dt id="constriction.stream.model.Binomial"><code class="flex name class">
<span>class <span class="ident">Binomial</span></span>
<span>(</span><span>self, n=None, p=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Binomial distribution over the alphabet {0, 1, &hellip;, n}.</p>
<p>Models the number of successful trials out of <code>n</code> trials where the trials are
independent from each other and each one succeeds with probability <code>p</code>.</p>
<h2 id="model-parameters">Model Parameters</h2>
<p>Each model parameter can either be specified as a scalar when constructing the model, or
as a rank-1 numpy array (with <code>dtype=np.int32</code> for <code>n</code> and <code>dtype=np.float64</code> for <code>p</code>)
when calling the entropy coder's encode or decode method (see <a href="#concrete-models-vs-model-families">discussion
above</a>). Note that, even if you delay all model
parameters to the point of encoding or decoding, then
you still have to <em>call</em> the
constructor of the model, i.e.: <code>model_family = constriction.stream.model.Binomial()</code>
&mdash; note the trailing <code>()</code>.</p>
<ul>
<li><strong>n</strong> &mdash; the number of trials;</li>
<li><strong>p</strong> &mdash; the probability that any given trial succeeds; must be between 0.0 and 1.0
(both inclusive). For your convenience, <code><a title="constriction" href="../index.html">constriction</a></code> always assigns a (possibly
tiny but) nonzero probability to all symbols in the range {0, 1, &hellip;, n}, even if you
set <code>p = 0.0</code> or <code>p = 1.0</code> so that all symbols in this range can in principle be
encoded, albeit possibly at a high bitrate.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Model</li>
</ul>
</dd>
<dt id="constriction.stream.model.Categorical"><code class="flex name class">
<span>class <span class="ident">Categorical</span></span>
<span>(</span><span>self, probabilities=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A categorical distribution with explicitly provided probabilities.</p>
<p>Allows you to define any probability distribution over the alphabet <code>{0, 1, ... n-1}</code>
by explicitly providing the probability of each symbol in the alphabet.</p>
<h2 id="examples">Examples</h2>
<p>Using a <em>concrete</em> (i.e., fully parameterized) <code>CategoricalModel</code>:</p>
<pre><code class="language-python"># Define a categorical distribution over the (implied) alphabet {0,1,2,3}
# with P(X=0) = 0.2, P(X=1) = 0.4, P(X=2) = 0.1, and P(X=3) = 0.3:
probabilities = np.array([0.2, 0.4, 0.1, 0.3], dtype=np.float64)
model = constriction.stream.model.Categorical(probabilities)

# Encode and decode an example message:
symbols = np.array([0, 3, 2, 3, 2, 0, 2, 1], dtype=np.int32)
coder = constriction.stream.stack.AnsCoder() # (RangeEncoder also works)
coder.encode_reverse(symbols, model)
print(coder.get_compressed()) # (prints: [488222996, 175])

reconstructed = coder.decode(model, 8) # (decodes 8 i.i.d. symbols)
assert np.all(reconstructed == symbols) # (verify correctness)
</code></pre>
<p>Using a model <em>family</em> so that we can provide individual probabilities for each
encoded or decoded symbol:</p>
<pre><code class="language-python"># Define 3 categorical distributions, each over the alphabet {0,1,2,3,4}:
model_family = constriction.stream.model.Categorical() # note empty `()`
probabilities = np.array(
    [[0.3, 0.1, 0.1, 0.3, 0.2],  # (for symbols[0])
     [0.1, 0.4, 0.2, 0.1, 0.2],  # (for symbols[1])
     [0.4, 0.2, 0.1, 0.2, 0.1]], # (for symbols[2])
    dtype=np.float64)

symbols = np.array([0, 4, 1], dtype=np.int32)
coder = constriction.stream.stack.AnsCoder() # (RangeEncoder also works)
coder.encode_reverse(symbols, model_family, probabilities)
print(coder.get_compressed()) # (prints: [152672664])

reconstructed = coder.decode(model_family, probabilities)
assert np.all(reconstructed == symbols) # (verify correctness)
</code></pre>
<h2 id="model-parameters">Model Parameters</h2>
<ul>
<li><strong>probabilities</strong> &mdash; the probability table, as a numpy array. You can specify the
probabilities either directly when constructing the model by passing a rank-1 numpy
array with <code>dtype=np.float64</code> and length <code>n</code> to the constructor; or you can call the
constructor with no arguments and instead provide a rank-2 tensor of shape <code>(m, n)</code>
when encoding or decoding an array of <code>m</code> symbols, as in the second example above.</li>
</ul>
<p>The probability table for each symbol must be normalizable (i.e., all probabilities must
be nonnegative and finite), but the probabilities don't necessarily have to sum to one.
They will automatically be rescaled to an exactly normalized distribution. Further,
<code><a title="constriction" href="../index.html">constriction</a></code> guarantees to assign at least the smallest representable nonzero
probability to all symbols from the range <code>{0, 1, ..., n-1}</code> (where <code>n</code> is the number of
provided probabilities), even if the provided probability for some symbol is smaller
than the smallest representable probability (including if it is exactly <code>0.0</code>). This
ensures that all symbols from this range can in principle be encoded.</p>
<p>Note that, if you delay providing the probabilities until encoding or decoding as in
the second example above, you still have to <em>call</em> the constructor of the model, i.e.,
<code>model_family = constriction.stream.model.Categorical()</code> &mdash; note the empty parentheses
<code>()</code> at the end.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Model</li>
</ul>
</dd>
<dt id="constriction.stream.model.CustomModel"><code class="flex name class">
<span>class <span class="ident">CustomModel</span></span>
<span>(</span><span>self, cdf, approximate_inverse_cdf, min_symbol_inclusive, max_symbol_inclusive)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper for a model (or model family) defined via custom callback functions</p>
<p>A <code><a title="constriction.stream.model.CustomModel" href="#constriction.stream.model.CustomModel">CustomModel</a></code> provides maximum flexibility for defining entropy models. It
encapsulates a user-defined cumulative distribution function (CDF) and the corresponding
quantile function (inverse of the CDF, also called percent point function or PPF).</p>
<p>A <code><a title="constriction.stream.model.CustomModel" href="#constriction.stream.model.CustomModel">CustomModel</a></code> can define either a concrete model or a model family (see
<a href="#concrete-models-vs-model-families">discussion above</a>). To define a model family, the
provided callbacks for the CDF and PPF should expect additional model parameters, see
second example below.</p>
<h2 id="before-you-read-on">Before You Read on</h2>
<p>If you use the <code>scipy</code> python package for defining your entropy model, then there's no
need to use <code><a title="constriction.stream.model.CustomModel" href="#constriction.stream.model.CustomModel">CustomModel</a></code>. The adapter
<a href="#constriction.stream.model.ScipyModel"><code>ScipyModel</code></a> will be more convenient.</p>
<h2 id="examples">Examples</h2>
<p>Using a <em>concrete</em> (i.e., fully parameterized) custom model:</p>
<pre><code class="language-python">model = constriction.stream.model.CustomModel(
    lambda x: ... TODO ...,  # define your CDF here
    lambda xi: ... TODO ..., # provide an approximate inverse of the CDF
   -100, 100) # (or whichever range your model has)

# Encode and decode an example message:
symbols = np.array([... TODO ...], dtype=np.int32)
coder = constriction.stream.stack.AnsCoder() # (RangeEncoder also works)
coder.encode_reverse(symbols, model)
print(coder.get_compressed())

reconstructed = coder.decode(model, 5) # (decodes 5 i.i.d. symbols)
assert np.all(reconstructed == symbols) # (verify correctness)
</code></pre>
<p>Using a model <em>family</em> so that we can provide individual model parameters for each
encoded or decoded symbol:</p>
<pre><code class="language-python">model_family = constriction.stream.model.CustomModel(
    lambda x, model_param1, model_param2: ... TODO ...,  # CDF
    lambda xi, model_param1, model_param2: ... TODO ..., # PPF
   -100, 100) # (or whichever range your model has)

# Encode and decode an example message with per-symbol model parameters:
symbols       = np.array([... TODO ...], dtype=np.int32)
model_params1 = np.array([... TODO ...], dtype=np.float64)
model_params2 = np.array([... TODO ...], dtype=np.float64)
coder = constriction.stream.stack.AnsCoder() # (RangeEncoder also works)
coder.encode_reverse(symbols, model_family, model_params1, model_params2)
print(coder.get_compressed())

reconstructed = coder.decode(model_family, model_params1, model_params2)
assert np.all(reconstructed == symbols) # (verify correctness)
</code></pre>
<h2 id="arguments">Arguments</h2>
<p>The following arguments always have to be provided directly to the constructor of the
model. They cannot be delayed until encoding or decoding. However, you may provide
callback functions <code>cdf</code> and <code>approximate_inverse_cdf</code> that expect additional model
parameters, which you then pass in as numpy arrays when calling the entropy coder's
encode or decode method, see second example above.</p>
<ul>
<li><strong>cdf</strong> &mdash; the cumulative distribution function; a nondecreasing function that
returns a scalar between 0.0 and 1.0 (both inclusive), and which <code><a title="constriction" href="../index.html">constriction</a></code> will
evaluate on mid-points between integers in order to integrate the probability
distribution over bins centered at each integer. The function signature must be
<code>cdf(x, [param1, [param2, [param3, &hellip;]]])</code> where <code>x</code> is the value at which
<code><a title="constriction" href="../index.html">constriction</a></code> will evaluate the CDF and <code>paramX</code> will be provided if the
<code><a title="constriction.stream.model.CustomModel" href="#constriction.stream.model.CustomModel">CustomModel</a></code> is used as a model <em>family</em>, as in the second example above.</li>
<li><strong>approximate_inverse_cdf</strong> &mdash; the inverse of the CDF, also called quantile function
or percent point function (PPF). This function does not have to return very precise
results since <code><a title="constriction" href="../index.html">constriction</a></code> will use the provided <code>cdf</code> as the defining source of
truth and invert it exactly; the provided <code>approximate_inverse_cdf</code> is only used to
speed up the function inversion. The function signature must be analogous to above,
<code>approximate_inverse_cdf(xi, [param1, [param2, [param3, &hellip;]]])</code>, where you may rely
on <code>0.0 &lt;= xi &lt;= 1.0</code>.</li>
<li><strong>min_symbol_inclusive</strong> and <strong>max_symbol_inclusive</strong> &mdash; define the range of integer
symbols that you will be able to encode with this model, see "Guarantees And
Requirements" below.</li>
</ul>
<h2 id="guarantees-and-requirements">Guarantees And Requirements</h2>
<p>The <code><a title="constriction" href="../index.html">constriction</a></code> library takes care of ensuring that the resulting entropy model is
<em>exactly</em> invertible, which is crucial for correct encoding/decoding, and which is
nontrivial due to inevitable rounding errors. In addition, <code><a title="constriction" href="../index.html">constriction</a></code> ensures that
all symbols within the provided range {<code>min_symbol_inclusive</code>, &hellip;,
<code>max_symbol_inclusive</code>} are assigned a nonzero probability (even if their actual
probability under the provided model is smaller than the smallest representable
probability), and that the probabilities of all symbols within this range add up to
<em>exactly</em> one, without rounding errors. This is important to ensure that all symbols
within the provided range can indeed be encoded, and that encoding with ANS is
surjective.</p>
<p>The above guarantees hold only as long as the provided CDF is nondecreasing, can be
evaluated on mid-points between integers, and returns a value &gt;= 0.0 and &lt;= 1.0
everywhere.</p></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Model</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li>builtins.ScipyModel</li>
</ul>
</dd>
<dt id="constriction.stream.model.Model"><code class="flex name class">
<span>class <span class="ident">Model</span></span>
<span>(</span><span>self, NOT_INSTANTIABLE)</span>
</code></dt>
<dd>
<div class="desc"><p>Abstract base class for all entropy models.</p>
<p>This class cannot be instantiated. Instantiate one of its concrete subclasses instead.</p></div>
<h3>Subclasses</h3>
<ul class="hlist">
<li>builtins.Bernoulli</li>
<li>builtins.Binomial</li>
<li>builtins.Categorical</li>
<li>builtins.CustomModel</li>
<li>builtins.QuantizedCauchy</li>
<li>builtins.QuantizedGaussian</li>
<li>builtins.QuantizedLaplace</li>
<li>builtins.Uniform</li>
</ul>
</dd>
<dt id="constriction.stream.model.QuantizedCauchy"><code class="flex name class">
<span>class <span class="ident">QuantizedCauchy</span></span>
<span>(</span><span>self, min_symbol_inclusive, max_symbol_inclusive, loc=None, scale=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Cauchy distribution, quantized over bins of size 1 centered at integer values.</p>
<p>Analogous to <a href="#constriction.stream.model.QuantizedGaussian"><code>QuantizedGaussian</code></a>, just
starting from a Cauchy distribution rather than a Gaussian.</p>
<p>Before quantization, the probability density function of a Cauchy distribution is:</p>
<p><code>p(x) = 1 / (pi * gamma * (1 + ((x - loc) / gamma)^2))</code></p>
<p>where the parameters <code>loc</code> and <code>scale</code> parameterize the location of the mode and the
width of the distribution.</p>
<h2 id="fixed-arguments">Fixed Arguments</h2>
<p>The following arguments always have to be provided directly to the constructor of the
model. They cannot be delayed until encoding or decoding.</p>
<ul>
<li><strong>min_symbol_inclusive</strong> and <strong>max_symbol_inclusive</strong> &mdash; specify the integer range on
which the model is defined.</li>
</ul>
<h2 id="model-parameters">Model Parameters</h2>
<p>Each of the following model parameters can either be specified as a scalar when
constructing the model, or as a rank-1 numpy array (with <code>dtype=np.float64</code>) when
calling the entropy coder's encode or decode method.</p>
<ul>
<li><strong>loc</strong> &mdash; the location (mode) of the Cauchy distribution before quantization.</li>
<li><strong>scale</strong> &mdash; the scale parameter <code>gamma</code> of the Cauchy distribution before
quantization (resulting in a full width at half maximum of <code>2 * scale</code>).</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Model</li>
</ul>
</dd>
<dt id="constriction.stream.model.QuantizedGaussian"><code class="flex name class">
<span>class <span class="ident">QuantizedGaussian</span></span>
<span>(</span><span>self, min_symbol_inclusive, max_symbol_inclusive, mean=None, std=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Gaussian distribution, quantized over bins of size 1 centered at integer values.</p>
<p>This kind of entropy model is often used in novel deep-learning based compression
methods. If you need a quantized continuous distribution that is not a Gaussian or a
Laplace, then maybe <a href="#constriction.stream.model.ScipyModel"><code>ScipyModel</code></a> or
<a href="#constriction.stream.model.CustomModel"><code>CustomModel</code></a> is for you.</p>
<p>A <code><a title="constriction.stream.model.QuantizedGaussian" href="#constriction.stream.model.QuantizedGaussian">QuantizedGaussian</a></code> distribution is a probability distribution over the alphabet
<code>{-min_symbol_inclusive, -min_symbol_inclusive + 1, ..., max_symbol_inclusive}</code>. It is
defined by taking a Gaussian (or "Normal") distribution with the specified mean and
standard deviation, clipping it to the interval
<code>[-min_symbol_inclusive - 0.5, max_symbol_inclusive + 0.5]</code>, renormalizing it to account
for the clipped off tails, and then integrating the probability density over the bins
<code>[symbol - 0.5, symbol + 0.5]</code> for each <code><a title="constriction.symbol" href="../symbol.html">constriction.symbol</a></code> in the above alphabet. We further
guarantee that all symbols within the above alphabet are assigned at least the smallest
representable nonzero probability (and thus can, in principle, be encoded), even if the
true probability mass on the interval <code>[symbol - 0.5, symbol + 0.5]</code> integrates to a
value that is smaller than the smallest representable nonzero probability.</p>
<h2 id="examples">Examples</h2>
<p>See <a href="#examples">module level examples</a>.</p>
<h2 id="fixed-arguments">Fixed Arguments</h2>
<p>The following arguments always have to be provided directly to the constructor of the
model. They cannot be delayed until encoding or decoding.</p>
<ul>
<li><strong>min_symbol_inclusive</strong> and <strong>max_symbol_inclusive</strong> &mdash; specify the integer range on
which the model is defined.</li>
</ul>
<h2 id="model-parameters">Model Parameters</h2>
<p>Each of the following model parameters can either be specified as a scalar when
constructing the model, or as a rank-1 numpy array (with <code>dtype=np.float64</code>) when
calling the entropy coder's encode or decode method.</p>
<ul>
<li><strong>mean</strong> &mdash; the mean of the Gaussian distribution before quantization.</li>
<li><strong>std</strong> &mdash; the standard deviation of the Gaussian distribution before quantization.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Model</li>
</ul>
</dd>
<dt id="constriction.stream.model.QuantizedLaplace"><code class="flex name class">
<span>class <span class="ident">QuantizedLaplace</span></span>
<span>(</span><span>self, min_symbol_inclusive, max_symbol_inclusive, mean=None, scale=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A Laplace distribution, quantized over bins of size 1 centered at integer values.</p>
<p>Analogous to <a href="#constriction.stream.model.QuantizedGaussian"><code>QuantizedGaussian</code></a>, just
starting from a Laplace distribution rather than a Gaussian.</p>
<h2 id="fixed-arguments">Fixed Arguments</h2>
<p>The following arguments always have to be provided directly to the constructor of the
model. They cannot be delayed until encoding or decoding.</p>
<ul>
<li><strong>min_symbol_inclusive</strong> and <strong>max_symbol_inclusive</strong> &mdash; specify the integer range on
which the model is defined.</li>
</ul>
<h2 id="model-parameters">Model Parameters</h2>
<p>Each of the following model parameters can either be specified as a scalar when
constructing the model, or as a rank-1 numpy array (with <code>dtype=np.float64</code>) when
calling the entropy coder's encode or decode method.</p>
<ul>
<li><strong>mean</strong> &mdash; the mean of the Laplace distribution before quantization.</li>
<li><strong>scale</strong> &mdash; the scale parameter <code>b</code> of the Laplace distribution before quantization
(resulting in a variance of <code>2 * scale**2</code>).</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Model</li>
</ul>
</dd>
<dt id="constriction.stream.model.ScipyModel"><code class="flex name class">
<span>class <span class="ident">ScipyModel</span></span>
<span>(</span><span>self, scipy_model, min_symbol_inclusive, max_symbol_inclusive)</span>
</code></dt>
<dd>
<div class="desc"><p>Adapter for models and model families from the <code>scipy</code> python package.</p>
<p>This is similar to <code><a title="constriction.stream.model.CustomModel" href="#constriction.stream.model.CustomModel">CustomModel</a></code> but easier to use if your model's cumulative
distribution function and percent point function are already implemented in the popular
<code>scipy</code> python package. Just provide either a fully parameterized scipy-model or a scipy
model-class to the constructor. The adapter can be used both with both discrete models
(over a continuous integer domain) and continuous models. Continuous models will be
quantized to bins of width 1 centered at integers, analogous to the procedure described
in the documentation of
<a href="#constriction.stream.model.QuantizedGaussian"><code>QuantizedGaussian</code></a></p>
<h2 id="compatibility-warning">Compatibility Warning</h2>
<p>The <code>scipy</code> package provides some of the same models for which <code><a title="constriction" href="../index.html">constriction</a></code> offers
builtin models too (e.g., Gaussian, Laplace, Binomial). While wrapping, e.g.,
<code>scipy.stats.norm</code> in a <code><a title="constriction.stream.model.ScipyModel" href="#constriction.stream.model.ScipyModel">ScipyModel</a></code> will result in an entropy model that is <em>similar</em>
to a <code><a title="constriction.stream.model.QuantizedGaussian" href="#constriction.stream.model.QuantizedGaussian">QuantizedGaussian</a></code> with the same parameters, the two models will differ slightly
due to different rounding operations. Even such tiny differences can have catastrophic
effects when the models are used for entropy coding. Thus, always make sure you use the
same implementation of entropy models on the encoder and decoder side. Generally prefer
<code><a title="constriction" href="../index.html">constriction</a></code>'s builtin models since they are considerably faster and also available in
<code><a title="constriction" href="../index.html">constriction</a></code>'s Rust API.</p>
<h2 id="examples">Examples</h2>
<p>Using a <em>concrete</em> (i.e., fully parameterized) <code>scipy</code> model:</p>
<pre><code class="language-python">import scipy.stats

scipy_model = scipy.stats.cauchy(loc=6.7, scale=12.4)
model = constriction.stream.model.ScipyModel(scipy_model, -100, 100)

# Encode and decode an example message:
symbols = np.array([22, 14, 5, -3, 19, 7], dtype=np.int32)
coder = constriction.stream.stack.AnsCoder() # (RangeEncoder also works)
coder.encode_reverse(symbols, model)
print(coder.get_compressed()) # (prints: [3569876501    1944098])

reconstructed = coder.decode(model, 6) # (decodes 6 i.i.d. symbols)
assert np.all(reconstructed == symbols) # (verify correctness)
</code></pre>
<p>Using a model <em>family</em> so that we can provide individual model parameters for each
encoded or decoded symbol:</p>
<pre><code class="language-python">import scipy.stats

scipy_model_family = scipy.stats.cauchy
model_family = constriction.stream.model.ScipyModel(
    scipy_model_family, -100, 100)

# Encode and decode an example message with per-symbol model parameters:
symbols = np.array([22,   14,   5,   -3,   19,   7  ], dtype=np.int32)
locs    = np.array([26.2, 10.9, 8.7, -6.3, 25.1, 8.9], dtype=np.float64)
scales  = np.array([ 4.3, 7.4,  2.9,  4.1,  9.7, 3.4], dtype=np.float64)
coder = constriction.stream.stack.AnsCoder() # (RangeEncoder also works)
coder.encode_reverse(symbols, model_family, locs, scales)
print(coder.get_compressed()) # (prints: [3493721376, 17526])

reconstructed = coder.decode(model_family, locs, scales)
assert np.all(reconstructed == symbols) # (verify correctness)
</code></pre>
<h2 id="arguments">Arguments</h2>
<p>The following arguments always have to be provided directly to the constructor of the
model. They cannot be delayed until encoding or decoding. However, the encapsulated
scipy model may expect additional model parameters, which you can pass in at encoding or
decoding time as in the second example below.</p>
<ul>
<li><strong>model</strong> &mdash; a <code>scipy</code> model or model class as in the examples above.</li>
<li><strong>min_symbol_inclusive</strong> and <strong>max_symbol_inclusive</strong> &mdash; define the range of integer
symbols that you will be able to encode with this model, see "Guarantees And
Requirements" below.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.CustomModel</li>
<li>builtins.Model</li>
</ul>
</dd>
<dt id="constriction.stream.model.Uniform"><code class="flex name class">
<span>class <span class="ident">Uniform</span></span>
<span>(</span><span>self, size=None)</span>
</code></dt>
<dd>
<div class="desc"><p>A uniform distribution over the alphabet <code>{0, 1, ..., size-1}</code>, where <code>size</code> is an
integer model parameter.</p>
<p>Due to rounding effects, the symbol <code>size-1</code> typically has very slightly higher probability
than the other symbols.</p>
<h2 id="model-parameter">Model Parameter</h2>
<p>The model parameter can either be specified as a scalar when constructing the model, or
as a rank-1 numpy array with <code>dtype=np.int32</code> when calling the entropy coder's encode
or decode method. Note that, in the latter case, you still have to <em>call</em> the
constructor of the model, i.e.: <code>model_family = constriction.stream.model.Uniform()</code>
&mdash; note the trailing <code>()</code>.</p>
<ul>
<li><strong>size</strong> &mdash; the size of the alphabet / domain of the model. Must be at least 2 since
<code><a title="constriction" href="../index.html">constriction</a></code> cannot model delta distributions. Must be smaller than
<code>2**24</code> â‰ˆ 17 millions.</li>
</ul></div>
<h3>Ancestors</h3>
<ul class="hlist">
<li>builtins.Model</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#concrete-models-vs-model-families">Concrete Models vs. Model Families</a></li>
<li><a href="#examples">Examples</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="constriction.stream" href="../stream.html">constriction.stream</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="constriction.stream.model.Bernoulli" href="#constriction.stream.model.Bernoulli">Bernoulli</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.Binomial" href="#constriction.stream.model.Binomial">Binomial</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.Categorical" href="#constriction.stream.model.Categorical">Categorical</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.CustomModel" href="#constriction.stream.model.CustomModel">CustomModel</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.Model" href="#constriction.stream.model.Model">Model</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.QuantizedCauchy" href="#constriction.stream.model.QuantizedCauchy">QuantizedCauchy</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.QuantizedGaussian" href="#constriction.stream.model.QuantizedGaussian">QuantizedGaussian</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.QuantizedLaplace" href="#constriction.stream.model.QuantizedLaplace">QuantizedLaplace</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.ScipyModel" href="#constriction.stream.model.ScipyModel">ScipyModel</a></code></h4>
</li>
<li>
<h4><code><a title="constriction.stream.model.Uniform" href="#constriction.stream.model.Uniform">Uniform</a></code></h4>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>